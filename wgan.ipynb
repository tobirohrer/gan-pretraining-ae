{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import os, os.path\n",
    "#import tensorflow_addons as tfa\n",
    "\n",
    "import math\n",
    "import json\n",
    "\n",
    "import sklearn.metrics\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "PATCH_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "NOISE_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH_TRAINING = '../../study/biometric/seminar/data/LivDet-Fingerprint/livdet21/Dermalog/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create shuffeled TF-Datasets containing the paths to the files\n",
    "def shuffle_paths(ds_paths, shuffle_loops):\n",
    "    #see https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle/48096625#48096625\n",
    "    list_paths = list(ds_paths.as_numpy_iterator())\n",
    "    for i in range(shuffle_loops):\n",
    "        random.seed(4)\n",
    "        random.shuffle(list_paths)\n",
    "    return tf.data.Dataset.from_tensor_slices(list_paths)\n",
    "\n",
    "#train paths only contain live fingerprints\n",
    "ds_train_paths = tf.data.Dataset.list_files(str(PATH_TRAINING + '*/Live/*.png'), seed=4)\n",
    "ds_train_paths = shuffle_paths(ds_train_paths,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    if parts[-2] == 'Live':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def decode_bmp(file_path):\n",
    "    file = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_bmp(file, channels=1)\n",
    "    return img    \n",
    "\n",
    "def decode_png(file_path):\n",
    "    file = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_png(file, channels=1)\n",
    "    return img\n",
    "\n",
    "def equalize_hist(img):\n",
    "    img_zero_map = (img != 255);\n",
    "    hist, bins = np.histogram(img[img_zero_map], 256,[0,255])\n",
    "    cdf = hist.cumsum()\n",
    "    cdf = (cdf - cdf.min())*255/(cdf.max()-cdf.min())\n",
    "    cdf = np.ma.filled(cdf, 255).astype('uint8')\n",
    "    return cdf[img]\n",
    "\n",
    "def exctract_roi(img):\n",
    "    # Extract region of intrest by simply removing empty surrounding pixels.\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "\n",
    "    y_start = 0\n",
    "    y_stop = img_height\n",
    "    x_start = 0\n",
    "    x_stop = img_width\n",
    "    \n",
    "    for i in range(img_height):\n",
    "        if tf.math.reduce_sum(img[i], axis=None, keepdims=False, name=None) != img_width:\n",
    "            y_start = i\n",
    "            break\n",
    "\n",
    "    for i in range(img_height-1, 0, -1):\n",
    "        if tf.math.reduce_sum(img[i], axis=None, keepdims=False, name=None) != img_width:\n",
    "            y_stop = i\n",
    "            break\n",
    "\n",
    "    for i in range(img_width):\n",
    "        if tf.math.reduce_sum(img[:,i], axis=None, keepdims=False, name=None) != img_height:\n",
    "            x_start = i\n",
    "            break\n",
    "\n",
    "    for i in range(img_width-1, 0, -1):\n",
    "        if tf.math.reduce_sum(img[:,i], axis=None, keepdims=False, name=None) != img_height:\n",
    "            x_stop = i\n",
    "            break\n",
    "\n",
    "    img = img[y_start:y_stop,x_start:x_stop]\n",
    "    img = (img-1)*-1\n",
    "        \n",
    "    return img\n",
    "\n",
    "def get_random_patch(image):\n",
    "    # Cropping random patch from input image\n",
    "    non_zero_count = 0\n",
    "    loop_count = 0\n",
    "    #making sure the crop does not contain mainly void.\n",
    "    while non_zero_count < 1900:\n",
    "        loop_count += 1\n",
    "        cropped = tf.image.random_crop(image, [PATCH_SIZE, PATCH_SIZE,IMG_CHANNELS], seed=None, name=None)\n",
    "        #cropped = tf.image.resize(cropped, [IMG_HEIGHT, IMG_WIDTH])\n",
    "        non_zero_count = tf.math.count_nonzero(cropped)\n",
    "        if loop_count > 10:\n",
    "            return cropped\n",
    "    return cropped\n",
    "\n",
    "def process_path(file_path):\n",
    "    # Wire preprocessing together\n",
    "    label = get_label(file_path)\n",
    "    img = decode_png(file_path)\n",
    "    \n",
    "    #normalize img data to [0,1) scale\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    \n",
    "    img = exctract_roi(img)\n",
    "\n",
    "    #for transfer learning which nets which are trained on RGB imges\n",
    "    if IMG_CHANNELS == 3:\n",
    "        img = tf.concat([img,img,img], 2)\n",
    "        \n",
    "    return img, label\n",
    "\n",
    "def gan_rescale(image, label):\n",
    "    return image*2-1, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define mappable functions to run custom python code in tf\n",
    "def mappable_get_random_patch(image,label):\n",
    "    random_patch = tf.py_function(func=get_random_patch,\n",
    "                                inp=[image],\n",
    "                                Tout=(tf.float32))\n",
    "    result_tensor = random_patch, label\n",
    "    result_tensor[0].set_shape((PATCH_SIZE, PATCH_SIZE, IMG_CHANNELS))\n",
    "    result_tensor[1].set_shape(())\n",
    "    return result_tensor\n",
    "\n",
    "\n",
    "def mappable_fn_patch(x):\n",
    "    result_tensor = tf.py_function(func=process_path,\n",
    "                                inp=[x],\n",
    "                                Tout=(tf.float32,tf.uint8))\n",
    "    return result_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def augment(image,label):\n",
    "    image = tf.image.random_flip_left_right(image, seed=None)\n",
    "    \n",
    "    #degrees = tf.random.uniform([], minval=-20, maxval=20, dtype=tf.dtypes.float32, seed=None, name=None)\n",
    "    #image = tfa.image.transform_ops.rotate(image, degrees * math.pi/180)\n",
    "    \n",
    "    brightness = tf.random.uniform([], minval=0.75, maxval=1.25, dtype=tf.dtypes.float32, seed=None, name=None)\n",
    "    image = image*brightness\n",
    "    image = tf.clip_by_value(image, 0, 1, name=None)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets for Patch Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_patch_train = (ds_train_paths\n",
    "            .map(mappable_fn_patch, num_parallel_calls=AUTOTUNE)\n",
    "            .cache()\n",
    "            .shuffle(buffer_size=4000)\n",
    "            .map(augment, num_parallel_calls=AUTOTUNE) # randomizes the image based on augmentation rules\n",
    "            .map(mappable_get_random_patch)\n",
    "            .map(gan_rescale)\n",
    "            .batch(BATCH_SIZE, drop_remainder=True)\n",
    "            .prefetch(buffer_size=AUTOTUNE)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = RandomNormal(stddev=0.02)\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(4*4*1024, use_bias = False, input_shape = (200,), kernel_initializer=init))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Reshape((4, 4, 1024)))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(512, (5, 5), strides = (2,2), padding = \"same\", use_bias = False, kernel_initializer=init))\n",
    "    assert model.output_shape == (None, 8, 8, 512)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(256, (5,5), strides = (2,2), padding = 'same', use_bias = False, kernel_initializer=init))\n",
    "    assert model.output_shape == (None, 16, 16, 256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5,5), strides = (2,2), padding = 'same', use_bias = False, kernel_initializer=init))\n",
    "    assert model.output_shape == (None, 32, 32, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1, (5,5), strides = (2,2), padding = 'same', use_bias = False, activation = 'tanh', kernel_initializer=init))\n",
    "    assert model.output_shape == (None, 64, 64, 1)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[64, 64, 1], kernel_initializer=init))\n",
    "    assert model.output_shape == (None, 32, 32, 64)\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same', kernel_initializer=init))\n",
    "    assert model.output_shape == (None, 16, 16, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same', kernel_initializer=init))\n",
    "    assert model.output_shape == (None, 8, 8, 256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same', kernel_initializer=init))\n",
    "    assert model.output_shape == (None, 4, 4, 512)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1,activation='linear'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining WGAN\n",
    "\n",
    "This code is copied from: https://keras.io/examples/generative/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        discriminator,\n",
    "        generator,\n",
    "        latent_dim,\n",
    "        discriminator_extra_steps=3,\n",
    "        gp_weight=10.0,\n",
    "    ):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = discriminator_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(WGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\"Calculates the gradient penalty.\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "\n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # For each batch, we are going to perform the\n",
    "        # following steps as laid out in the original paper:\n",
    "        # 1. Train the generator and get the generator loss\n",
    "        # 2. Train the discriminator and get the discriminator loss\n",
    "        # 3. Calculate the gradient penalty\n",
    "        # 4. Multiply this gradient penalty with a constant weight factor\n",
    "        # 5. Add the gradient penalty to the discriminator loss\n",
    "        # 6. Return the generator and discriminator losses as a loss dictionary\n",
    "\n",
    "        # Train the discriminator first. The original paper recommends training\n",
    "        # the discriminator for `x` more steps (typically 5) as compared to\n",
    "        # one step of the generator. Here we will train it for 3 extra steps\n",
    "        # as compared to 5 to reduce the training time.\n",
    "        for i in range(self.d_steps):\n",
    "            # Get the latent vector\n",
    "            random_latent_vectors = tf.random.uniform(\n",
    "                shape=(batch_size, self.latent_dim), minval=-1,maxval=1\n",
    "            )\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                fake_images = self.generator(random_latent_vectors, training=True)\n",
    "                # Get the logits for the fake images\n",
    "                fake_logits = self.discriminator(fake_images, training=True)\n",
    "                # Get the logits for the real images\n",
    "                real_logits = self.discriminator(real_images, training=True)\n",
    "\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(d_gradient, self.discriminator.trainable_variables)\n",
    "            )\n",
    "\n",
    "        # Train the generator\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.uniform(shape=(batch_size, self.latent_dim), minval=-1,maxval=1)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            generated_images = self.generator(random_latent_vectors, training=True)\n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator(generated_images, training=True)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_img_logits)\n",
    "\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n",
    "    \n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=6, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        random_latent_vectors = tf.random.uniform(shape=(self.num_img, self.latent_dim), minval=-1,maxval=1)\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images = (generated_images * 127.5) + 127.5\n",
    "\n",
    "        for i in range(self.num_img):\n",
    "            img = generated_images[i].numpy()\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            \n",
    "cbk = GANMonitor(num_img=5, latent_dim=NOISE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = keras.optimizers.Adam(\n",
    "        learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "discriminator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "\n",
    "# Define the loss functions for the discriminator,\n",
    "# which should be (fake_loss - real_loss).\n",
    "# We will add the gradient penalty later to this loss function.\n",
    "def discriminator_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "\n",
    "# Define the loss functions for the generator.\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)\n",
    "\n",
    "# Get the wgan model\n",
    "wgan = WGAN(\n",
    "    discriminator=make_discriminator_model(),\n",
    "    generator=make_generator_model(),\n",
    "    latent_dim=NOISE_DIM,\n",
    "    discriminator_extra_steps=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    "    g_loss_fn=generator_loss,\n",
    "    d_loss_fn=discriminator_loss,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "wgan.fit(ds_patch_train, batch_size=BATCH_SIZE, epochs=100, callbacks=[cbk])                                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random latent space and create fingerprint patch using generator\n",
    "latent_space = np.random.uniform(size=(1,200), low=-1, high=1)\n",
    "img = wgan.generator(latent_space)\n",
    "plt.imshow(img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wgan.generator.save_weights('./gen/')\n",
    "wgan.discriminator.save_weights('./disc/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
